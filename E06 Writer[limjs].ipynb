{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seventh-spencer",
   "metadata": {},
   "source": [
    "# 6. 프로젝트: 멋진 작사가 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-trouble",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 다운로드  \n",
    "먼저 아래 링크에서 Song Lyrics 데이터를 다운로드  \n",
    "저장된 파일을 압축 해제한 후, 모든 txt 파일을 lyrics 폴더를 만들어 그 속에 저장  \n",
    "* Song Lyrics  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-overhead",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 읽어오기\n",
    "glob 모듈을 사용하면 파일을 읽어오는 작업을 하기  \n",
    "glob 를 활용하여 모든 txt 파일을 읽어온 후, raw_corpus 리스트에 문장 단위로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nasty-basement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['Ooh....... New York x2 Grew up in a town that is famous as a place of movie scenes', 'Noise is always loud, there are sirens all around and the streets are mean', \"If I can make it here, I can make it anywhere, that's what they say\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re                  # 정규표현식을 위한 Regex 지원 모듈 (문장 데이터를 정돈하기 위해) \n",
    "import numpy as np         # 변환된 문장 데이터(행렬)을 편하게 처리하기 위해\n",
    "import tensorflow as tf    # 대망의 텐서플로우!\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-watch",
   "metadata": {},
   "source": [
    "## Step 3. 데이터 정제  \n",
    "* 앞서 배운 테크닉들을 활용해 문장 생성에 적합한 모양새로 데이터를 정제  \n",
    "* preprocess_sentence() 함수를 활용해 데이터를 정제  \n",
    "* 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거  \n",
    "* 토큰의 개수가 15개를 넘어가는 문장을 학습데이터에서 제외  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "under-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Ooh....... New York x2 Grew up in a town that is famous as a place of movie scenes\n",
      "1 Noise is always loud, there are sirens all around and the streets are mean\n",
      "2 If I can make it here, I can make it anywhere, that's what they say\n",
      "3 Seeing my face in lights or my name on marquees found down on Broadway Even if it ain't all it seems, I got a pocket full of dreams\n",
      "4 Baby, I'm from New York\n",
      "5 Concrete jungle where dreams are made of\n",
      "6 There's nothing you can't do\n",
      "7 Now you're in New York\n",
      "8 These streets will make you feel brand new\n",
      "9 Big lights will inspire you\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
    "\n",
    "    if idx > 9: break   # 일단 문장 10개만 확인해 볼 겁니다.\n",
    "        \n",
    "    print(idx,sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "scheduled-burton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()       \n",
    "    # 소문자로 바꾸고 양쪽 공백을 삭제\n",
    "  \n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀝니다.\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        \n",
    "    # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  \n",
    "    # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  \n",
    "    # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>'      \n",
    "    # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))   \n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "clinical-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> noise is always loud , there are sirens all around and the streets are mean <end>',\n",
       " '<start> if i can make it here , i can make it anywhere , that s what they say <end>',\n",
       " '<start> baby , i m from new york <end>',\n",
       " '<start> concrete jungle where dreams are made of <end>',\n",
       " '<start> there s nothing you can t do <end>',\n",
       " '<start> now you re in new york <end>',\n",
       " '<start> these streets will make you feel brand new <end>',\n",
       " '<start> big lights will inspire you <end>',\n",
       " '<start> such a melting pot , on the corner selling rock , preachers pray to god <end>',\n",
       " '<start> hail a gypsy cab , takes me down from harlem to the brooklyn bridge <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 길이 긴 것 빼고 다시 \n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    \n",
    "    if len(sentence) == 0: continue\n",
    "    #if len(sentence) > 15: continue\n",
    "    if sentence[-1] == \":\": continue    \n",
    "    if len(sentence.split()) <= 15:  \n",
    "        \n",
    "        corpus.append(preprocess_sentence(sentence))\n",
    "        \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sealed-savings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 길이의 평균 :  48.769329460610486\n",
      "문장 길이의 최대 :  123\n",
      "문장 길이 표준 편차 :  15.156410324887432\n",
      "pad_sequences maxlen :  109\n",
      "전체 문장의 0.9998099277131334%가 maxlen 설정값 이내에 포함됩니다.\n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(corpus)\n",
    "\n",
    "#텍스트 데이터 문장길이의 리스트를 생성\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "#문장 길이의 평균값, 최대값, 표준편차를 계산\n",
    "print(\"문장 길이의 평균 : \", np.mean(num_tokens))\n",
    "print(\"문장 길이의 최대 : \", np.max(num_tokens))\n",
    "print(\"문장 길이 표준 편차 : \", np.std(num_tokens))\n",
    "\n",
    "#최대 길이 (평균 + 4*표준편차) 너무 길면 시간이 오래 걸린다. \n",
    "max_tokens = np.mean(num_tokens) +4*np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print(\"pad_sequences maxlen : \", maxlen)\n",
    "print(\"전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다.\".format(np.sum(num_tokens<max_tokens)/len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defensive-mexican",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj56/anaconda3/envs/aiffel/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#문장 길이 분포 확인\n",
    "plt.rcParams['figure.figsize'] = (6, 4)\n",
    "plt.rcParams['grid.color'] = '#F0F0F0'\n",
    "plt.rcParams['grid.linestyle'] = 'solid'\n",
    "sns.distplot(num_tokens)\n",
    "plt.style.use(\"bmh\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gross-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  26  169  945 ...   77  246    3]\n",
      " [  11   93    4 ...   43   70    3]\n",
      " [   2   51    4 ...    0    0    0]\n",
      " ...\n",
      " [   2    9  155 ...    0    0    0]\n",
      " [   2    8    9 ...    0    0    0]\n",
      " [   2    6 3081 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f04d3bf5690>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도로 전처리 로직을 추가할 수 있습니다. 이번에는 사용하지 않겠습니다.\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
    "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, maxlen = 15, padding='post')  \n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reflected-carolina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  26  169  945    4   62   77 3649   25  137    8]\n",
      " [  11   93    4    5   32   72   11 1543    4   17]\n",
      " [   2   51    4    5   22   74  155  707    3    0]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:3, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hindu-contributor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 길이 확인\n",
    "len(tensor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "substantial-health",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  11,   93,    4,    5,   32,   72,   11, 1543,    4,   17,   16,\n",
       "         39,   43,   70,    3], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "generic-spectrum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n",
      "26729\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break\n",
    "     \n",
    "print(len(tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wireless-offset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  26  169  945    4   62   77 3649   25  137    8    6  470   77  246]\n",
      "[ 169  945    4   62   77 3649   25  137    8    6  470   77  246    3]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다. \n",
    "#마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "tgt_input = tensor[:, 1:]    # tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-dynamics",
   "metadata": {},
   "source": [
    "## Step 4. 평가 데이터셋 분리\n",
    "\n",
    "* 훈련 데이터와 평가 데이터를 분리  \n",
    "* tokenize() 함수로 데이터를 Tensor로 변환한 후,  \n",
    "* sklearn 모듈의 train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 분리  \n",
    "* 단어장의 크기는 12,000 이상으로 설정\n",
    "* 총 데이터의 20%를 평가 데이터셋으로 사용\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = <코드 작성>  \n",
    "여기까지 올바르게 진행했을 경우, 아래 실행 결과를 확인  \n",
    "\n",
    "print(\"Source Train:\", enc_train.shape)  \n",
    "print(\"Target Train:\", dec_train.shape)  \n",
    "out:  \n",
    "\n",
    "Source Train: (124960, 14)  \n",
    "Target Train: (124960, 14)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "closing-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (134685, 14)\n",
      "Target Train: (134685, 14)\n",
      "Source Val: (33672, 14)\n",
      "Target Val: (33672, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2)\n",
    "print(\"Source Train:\", enc_train.shape)  \n",
    "print(\"Target Train:\", dec_train.shape)  \n",
    "print(\"Source Val:\", enc_val.shape)\n",
    "print(\"Target Val:\", dec_val.shape)\n",
    "#학습데이터 갯수 124960보다 작은 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "japanese-environment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168357\n",
      "657\n",
      "12001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "print(BUFFER_SIZE)\n",
    "\n",
    "print(steps_per_epoch)\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    "print(VOCAB_SIZE)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(BUFFER_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-aside",
   "metadata": {},
   "source": [
    "## Step 5. 인공지능 만들기  \n",
    "모델의 Embedding Size와 Hidden Size를 조절  \n",
    "10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계  \n",
    "(Loss는 아래 제시된 Loss 함수를 그대로 사용!)   \n",
    "멋진 모델이 생성한 가사 한 줄을 제출  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "retired-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "quality-blair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-9.86662708e-05, -1.44382384e-05,  1.67084538e-04, ...,\n",
       "         -8.66470436e-05, -8.41885339e-05,  9.44619678e-05],\n",
       "        [-4.74708417e-04,  1.33309557e-04,  3.50772141e-04, ...,\n",
       "         -4.81913856e-04,  2.09167933e-06,  6.35895703e-05],\n",
       "        [-6.41575898e-04,  3.07951908e-04,  4.93681582e-04, ...,\n",
       "         -5.62634261e-04,  5.45209105e-07,  2.00161303e-04],\n",
       "        ...,\n",
       "        [-1.63103908e-03,  8.65140930e-04,  1.79054390e-04, ...,\n",
       "         -2.13655550e-03, -1.62124285e-03, -1.03065732e-03],\n",
       "        [-1.94084027e-03,  7.30594620e-04,  3.89241992e-04, ...,\n",
       "         -2.49823299e-03, -1.85819541e-03, -1.07272749e-03],\n",
       "        [-2.24723085e-03,  5.97679813e-04,  5.78227628e-04, ...,\n",
       "         -2.82214535e-03, -2.01437995e-03, -1.08253094e-03]],\n",
       "\n",
       "       [[-9.86662708e-05, -1.44382384e-05,  1.67084538e-04, ...,\n",
       "         -8.66470436e-05, -8.41885339e-05,  9.44619678e-05],\n",
       "        [-5.67752431e-05,  1.28624970e-05,  3.05002468e-04, ...,\n",
       "         -1.08052256e-04, -1.87914469e-04,  2.55510473e-04],\n",
       "        [ 2.05221768e-05,  6.38507772e-05,  1.07078362e-04, ...,\n",
       "         -3.41815285e-05, -3.40881845e-04,  3.36318830e-04],\n",
       "        ...,\n",
       "        [-7.60294439e-04,  6.21801359e-04, -9.57368407e-04, ...,\n",
       "         -7.27991865e-04, -9.23446205e-04, -7.34982546e-04],\n",
       "        [-8.86877649e-04,  6.55722572e-04, -7.50390638e-04, ...,\n",
       "         -8.95685982e-04, -1.24090898e-03, -9.82317841e-04],\n",
       "        [-1.09405536e-03,  6.60438789e-04, -4.79008857e-04, ...,\n",
       "         -1.15363614e-03, -1.53942150e-03, -1.22483948e-03]],\n",
       "\n",
       "       [[-9.86662708e-05, -1.44382384e-05,  1.67084538e-04, ...,\n",
       "         -8.66470436e-05, -8.41885339e-05,  9.44619678e-05],\n",
       "        [ 1.41530050e-04, -7.36419606e-05,  7.95544838e-05, ...,\n",
       "         -1.28766987e-05, -2.81388435e-04,  3.20525753e-04],\n",
       "        [ 2.75568775e-04, -1.20570847e-04,  5.05621138e-05, ...,\n",
       "          9.78399694e-05, -6.12296164e-04,  4.79318376e-04],\n",
       "        ...,\n",
       "        [-2.21306784e-03, -2.38137989e-04,  7.34911766e-04, ...,\n",
       "         -3.00717726e-03, -1.95027119e-03, -8.25923635e-04],\n",
       "        [-2.58202245e-03, -1.98936221e-04,  8.58324172e-04, ...,\n",
       "         -3.28540080e-03, -1.91960996e-03, -8.74077203e-04],\n",
       "        [-2.91427434e-03, -1.72593456e-04,  9.61909362e-04, ...,\n",
       "         -3.51661048e-03, -1.85336126e-03, -8.92179203e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-9.86662708e-05, -1.44382384e-05,  1.67084538e-04, ...,\n",
       "         -8.66470436e-05, -8.41885339e-05,  9.44619678e-05],\n",
       "        [-3.15667538e-04,  7.64517099e-05,  3.22199048e-04, ...,\n",
       "          7.09968663e-05,  3.23447784e-05,  1.23430480e-04],\n",
       "        [-4.38043644e-04,  3.10044590e-04,  1.87645579e-04, ...,\n",
       "          2.77032494e-04,  1.37369410e-04,  1.76141810e-04],\n",
       "        ...,\n",
       "        [-2.97095557e-03,  1.85899626e-05,  5.40573034e-04, ...,\n",
       "         -3.02452152e-03, -1.43374782e-03, -1.28138182e-03],\n",
       "        [-3.24623054e-03, -3.20444524e-05,  7.03817059e-04, ...,\n",
       "         -3.30980937e-03, -1.45893183e-03, -1.29047525e-03],\n",
       "        [-3.49397934e-03, -7.75130102e-05,  8.46770010e-04, ...,\n",
       "         -3.54330475e-03, -1.44765677e-03, -1.26811548e-03]],\n",
       "\n",
       "       [[-9.86662708e-05, -1.44382384e-05,  1.67084538e-04, ...,\n",
       "         -8.66470436e-05, -8.41885339e-05,  9.44619678e-05],\n",
       "        [-1.49288826e-05,  1.95634231e-04,  1.96504858e-04, ...,\n",
       "         -7.27406732e-05, -2.83776200e-04,  2.70269491e-04],\n",
       "        [ 3.19133105e-04,  3.93544251e-05, -8.53945239e-05, ...,\n",
       "          4.76406676e-05, -2.00235823e-04,  2.19888854e-04],\n",
       "        ...,\n",
       "        [ 1.48927633e-04,  1.27015228e-03,  4.29271633e-04, ...,\n",
       "         -7.54251261e-04,  6.87162683e-04,  1.80390038e-04],\n",
       "        [ 1.87216632e-04,  1.46545318e-03,  7.42344593e-04, ...,\n",
       "         -6.81124337e-04,  7.48508319e-04,  4.04519582e-04],\n",
       "        [ 7.79956463e-05,  1.58803212e-03,  7.45152822e-04, ...,\n",
       "         -6.99460856e-04,  5.29282494e-04,  5.71580662e-04]],\n",
       "\n",
       "       [[-9.86662708e-05, -1.44382384e-05,  1.67084538e-04, ...,\n",
       "         -8.66470436e-05, -8.41885339e-05,  9.44619678e-05],\n",
       "        [-2.59064574e-04,  1.48872568e-04, -3.33244679e-06, ...,\n",
       "         -1.81637733e-04, -1.04127219e-04,  1.81028852e-04],\n",
       "        [-3.53359879e-04,  4.92460153e-04, -2.35221567e-04, ...,\n",
       "         -2.46708281e-04, -1.25870574e-04,  3.47557099e-04],\n",
       "        ...,\n",
       "        [ 4.17600124e-04,  2.27626646e-04, -5.92523065e-05, ...,\n",
       "         -8.32433507e-05, -1.68163166e-03, -1.57171438e-04],\n",
       "        [ 3.79274497e-05,  1.98222566e-04,  1.31420893e-04, ...,\n",
       "         -5.03791030e-04, -1.90843293e-03, -4.79015696e-04],\n",
       "        [-4.27128631e-04,  1.94714230e-04,  3.42312269e-04, ...,\n",
       "         -9.88571788e-04, -2.07935157e-03, -7.58099835e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "large-johnson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "526/526 [==============================] - 85s 162ms/step - loss: 3.6220 - val_loss: 3.2461\n",
      "Epoch 2/30\n",
      "526/526 [==============================] - 85s 162ms/step - loss: 3.1481 - val_loss: 3.0700\n",
      "Epoch 3/30\n",
      "526/526 [==============================] - 86s 163ms/step - loss: 2.9751 - val_loss: 2.9505\n",
      "Epoch 4/30\n",
      "526/526 [==============================] - 86s 163ms/step - loss: 2.8410 - val_loss: 2.8621\n",
      "Epoch 5/30\n",
      "263/526 [==============>...............] - ETA: 38s - loss: 2.7314"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "history = model.fit(dataset, epochs=30, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['loss']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'g', label = \"Loss\")\n",
    "plt.plot(epochs, val_loss, 'r', label = \"Val_loss\")\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "                                                                 tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> love is\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-shakespeare",
   "metadata": {},
   "source": [
    "## ♠ embedding_size = 512 hidden_size = 2048로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 512\n",
    "hidden_size = 2048\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "history = model.fit(dataset, epochs=30, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['loss']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'g', label = \"Loss\")\n",
    "plt.plot(epochs, val_loss, 'r', label = \"Val_loss\")\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "                                                                 tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> love is\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-scottish",
   "metadata": {},
   "source": [
    "# ◈ 루브릭  \n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.  \n",
    "\n",
    "평가문항/상세기준  \n",
    "1. 가사 텍스트 생성 모델이 정상적으로 동작하는가?  \n",
    "텍스트 제너레이션 결과가 그럴듯한 문장으로 생성되는가? \n",
    "\n",
    "\n",
    "2. 데이터의 전처리와 데이터셋 구성 과정이 체계적으로 진행되었는가?  \n",
    "특수문자 제거, 토크나이저 생성, 패딩처리 등의 과정이 빠짐없이 진행되었는가?  \n",
    "\n",
    "\n",
    "3. 텍스트 생성모델이 안정적으로 학습되었는가?  \n",
    "텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-diamond",
   "metadata": {},
   "source": [
    "# ◈ 결론 및 고찰 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-celtic",
   "metadata": {},
   "source": [
    "이전에 사용한 txt 파일 보다 더 풍부한 데이터를 사용하여 사전 Index를 만들고, 임베딩 벡터를 만들고, 학습을 해본 결과 start 단어 뒤에 오는 문장이 훨씬 자연스러워 짐을 알 수 있었다.\n",
    "예를 들어 이전에는 `i love` 를 입력했을 때 출력되는 값이 `i love thee not a jar o the clock behind` 였으나, 현재 개선된 학습 모델에서는 `i love`에 대해 `i love you`라고 답변이 나오고, `love is`에 대해서는 `love is it` 이라는 결과가 나옴을 알 수 있었다.   \n",
    "사용되는 정보의 양과 질이 좀더 결과에 좋은 영향을 미치지 않았나 생각해 보며, 또한 15개를 넘어가는 문장을 학습데이터에서 제외하고, 사전의 개수도 `7000에서 12000`으로 늘어난 것도 영향이 있다고 생각된다.  \n",
    "`validation loss결과`는 epoch이 30회 부터 1아래로 떨어지는 경향을 보였다.   \n",
    "embedding_size와 hidden_size를 크게 조절하여 모델 fit이 필요하다고 생각하여 결과를 얻어 보았다. validation loss가 `1.0633`에서 `1.0237`로 떨어져서 루브릭 기준의 2.2보다 더 훨씬 좋은 결과를 얻을 수 있었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-requirement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
